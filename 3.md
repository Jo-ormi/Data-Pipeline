# 3장. 공통 데이터 파이프라인 패턴

생성일: 2022년 3월 11일 오후 9:02

파이프라인은 다양한 목표와 제약 조건으로 구축된다.

1. 데이터를 거의 실시간으로 처리해야 하는가? 
2. 매일 업데이트 할 수 있는가?
3. 대시보드에서 사용하거나 기계 학습 모델에 대한 입력으로 사용하도록 모델링되는가?

많은 사용 사례로 확장 가능한 몇 가지 공통 패턴이 있는데, 이 장에서는 이러한 패턴을 정의한다.  
후속 장에서는 이를 기반으로 구축된 파이프라인을 구현한다.

### **ETL 및 ELT**

ETL 및 ELT은 데이터 웨어하우징 및 비즈니스 인텔리전스에서 널리 사용되는 패턴이다. 최근 몇 년 동안 그들은 프로덕션에서 실행되는 데이터 과학 및 기계 학습 모델을 위한 파이프라인 패턴에 영감을 주었다. 많은 사람들이 이 용어를 파이프라인이 따르는 패턴보다는 데이터 파이프라인과 동의어로 알고 있다.

두 패턴 모두 데이터 웨어하우스에 데이터를 공급하고, 분석가 및 보고 도구를 유용하게 만드는 데 사용되는 데이터 처리에 대한 접근 방식이다. 이 둘의 차이점은 마지막 두 단계(변환 및 로드)의 순서이지만 이 장 전체에서 설명하는 것처럼 둘 사이를 선택하는 데 있어 설계상의 의미는 상당하다.

먼저 **ETL과 ELT의 단계**를 살펴보자.

- ***추출* 단계(The *extract* step)**
: 로드 및 변환을 준비하기 위해 다양한 소스에서 데이터를 수집한다. 2장 에서는 이러한 출처의 다양성과 추출 방법에 대해 논의했다.
- ***로드* 단계(The *load* step)**
: 원시 데이터(ELT의 경우) 또는 완전히 변환된 데이터(ETL의 경우)를 최종 대상으로 가져온다. 어느 쪽이든 최종 결과는 데이터를 데이터 웨어하우스, 데이터 레이크 또는 기타 대상으로 로드하는 것이다.
- ***변환* 단계(The *transform s*tep)**
: 각 소스 시스템의 원시 데이터가 결합되고 형식화되는 단계이다. 분석가, 시각화 도구 또는 파이프라인이 제공하는 모든 사용 사례에 유용하다. 프로세스를 ETL로 설계했는지 ELT로 설계했는지에 관계없이 이 단계에는 많은 것이 있습니다. 이 모든 사항은 6장 에서 자세히 설명 한다.

### ****추출물과 부하의 분리****

추출 및 로드 단계의 조합을 종종 ***데이터 수집*** 이라고 한다. 특히 이 장의 뒷부분에서 정의되는 ELT 및 EtLT 하위 패턴(소문자 *t* 참고 )에서 추출 및 로드 기능은 종종 소프트웨어 프레임워크에서 밀접하게 결합되고 함께 묶인다. 

그러나 파이프라인을 설계할 때 서로 다른 시스템 및 인프라에서 추출 및 로드를 조정하는 복잡성으로 인해 두 단계를 별개로 고려하는 것이 좋다.

### **ETL에서 ELT의 출현**

ETL은 수십 년 동안 데이터 파이프라인 패턴의 황금 표준이었다. 여전히 사용되지만  현재 주로 클라우드( 2장 참조 )를 기반으로 하는 최신 유형의 데이터 웨어하우스를 바탕으로 ELT가 선택 패턴으로 등장했다. 

이유는 

1. 이전에는 데이터 팀이 방대한 양의 원시 데이터를 로드하고 사용 가능한 데이터 모델로 변환하는 데 필요한 스토리지 또는 컴퓨팅이 있는 데이터 웨어하우스에 액세스할 수 없었기 때문이다.
2. 당시 데이터 웨어하우스는 트랜잭션 사용 사례에는 잘 작동하는 행 기반 데이터베이스였지만 분석에서 흔히 볼 수 있는 대용량 대량 쿼리에는 적합하지 않았다. 따라서 데이터가 먼저 소스 시스템에서 추출된 다음 별도의 시스템에서 변환된 다음 분석 및 시각화 도구의 최종 데이터 모델링 및 쿼리를 통해 웨어하우스에 로드되었다.

오늘날 대부분의 데이터 웨어하우스는 비용 효율적인 방식으로 대규모 데이터 세트에 대한 대량 변환을 저장하고 실행할 수 있는 확장성이 뛰어난 열 기반 데이터베이스를 기반으로 한다. 컬럼 기반 데이터베이스의 I/O 효율성, 데이터 압축, 데이터를 처리하기 위해 함께 작동할 수 있는 여러 노드에 데이터 및 쿼리를 분산하는 기능 덕분에 상황이 바뀌었다. 

행 기반 데이터 웨어하우스와 열 기반 데이터 웨어하우스 간의 차이가 미치는 영향은 매우 중요하다. 그림 3-1 은 레코드가 MySQL 또는 Postgres와 같은 행 기반 데이터베이스의 디스크에 저장되는 방법의 예이다. 데이터베이스의 각 행은 각 레코드의 크기에 따라 하나 이상의 블록으로 디스크에 함께 저장된다. 레코드가 단일 블록보다 작거나 블록 크기로 깔끔하게 나눌 수 없는 경우 일부 디스크 공간을 사용하지 않은 상태로 남긴다.

![https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492087823/files/assets/dppr_0301.png](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492087823/files/assets/dppr_0301.png)

**그림 3-1. 행 기반 저장소 데이터베이스에 저장된 테이블. 각 블록은 테이블의 레코드(행)를 포함.**

저장을 위해 MySQL 데이터베이스를 활용하는 전자 상거래 웹 애플리케이션과 같은 OLTP(온라인 트랜잭션 처리) 데이터베이스 사용 사례를 생각해보자. 웹 앱은 주문 확인 페이지의 주문 세부 정보와 같이 종종 각 레코드의 여러 값을 포함하는 읽기 및 쓰기를 MySQL 데이터베이스에 요청하게 된다. 또한 한 번에 하나의 주문만 쿼리하거나 업데이트할 가능성이 높다. 따라서 응용 프로그램이 필요로 하는 데이터가 디스크에 근접하게 저장되고 한 번에 쿼리되는 데이터의 양이 적기 때문에 행 기반 저장소가 최적이다.

그러나 분석에서는 상황이 반대입니다. 적은 양의 데이터를 자주 읽고 쓰는 것보다, 많은 양의 데이터를 드물게 읽고 쓴다. 또한 분석 쿼리에 테이블의 열이 많이 또는 모두 필요할 가능성이 낮고, 열이 많은 테이블의 단일 열이 필요합니다.

다시 가상의 전자 상거래 에서 주문 테이블을 생각해보자. 무엇보다도 여기에는 주문 금액과 배송 국가가 포함된다. 한 번에 하나씩 주문을 처리하는 웹 애플리케이션과 달리 데이터 웨어하우스를 사용하는 분석가는 주문을 대량으로 분석하기를 원할 것이다. 또한 데이터 웨어하우스의 주문 데이터를 포함하는 테이블에는 예를 들어 주문한 고객에 대한 정보와 같은 MySQL 데이터베이스에 있는 여러 테이블의 값을 포함하는 추가 열이 있을 수 있다. 아마도 분석가는 현재 활성 계정이 있는 고객의 모든 주문을 요약하려고 하는 것이 좋을 것이다. 이러한 쿼리에는 수백만 개의 레코드가 포함될 수 있지만 OrderTotal 및 CustomerActive의 두 열에서만 읽을 수 있다. 결국, 분석은 OLTP에서와 같이 데이터를 생성하거나 변경하는 것이 아니라, 메트릭 파생 및 데이터 이해에 관한 것이다.

그림 3-2 에서 볼 수 있듯이 Snowflake 또는 Amazon Redshift와 같은 열 데이터베이스는 행이 아닌 열 단위로 디스크 블록에 데이터를 저장한다. 우리의 사용 사례에서 분석가가 작성한 쿼리는 MySQL 데이터베이스와 같은 행 기반 레코드를 저장하는 블록이 아니라 OrderTotal 및 CustomerActive 값을 저장하는 블록에만 액세스하면 된다. 따라서 분석가의 쿼리에 필요한 필터링 및 합산을 수행하기 위해 메모리에 로드할 데이터와 디스크 I/O가 적다. 마지막 이점은 단일 행 기반 레코드에서 발생하는 경향이 있는 여러 유형이 아니라 각 블록에 동일한 데이터 유형이 저장되기 때문에 블록을 완전히 활용하고 최적으로 압축할 수 있다는 사실 덕분에 스토리지가 감소한다는 것이다.

대체로 열 기반 데이터베이스의 출현은 데이터 웨어하우스 내에서 대규모 데이터 세트를 저장, 변환 및 쿼리하는 것이 효율적임을 의미한다. 데이터 엔지니어는 데이터를 추출하고 웨어하우스로 로드하는 것을 전문으로 하는 파이프라인 단계를 구축하여 이를 유리하게 사용할 수 있다. 따라서 ELT는 머신 러닝 및 데이터 제품 개발의 다른 사용 사례뿐만 아니라 데이터 웨어하우스 파이프라인을 위한 이상적인 패턴으로 자리 잡았다.

![https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492087823/files/assets/dppr_0302.png](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492087823/files/assets/dppr_0302.png)

**그림 3-2. 열 기반 저장소 데이터베이스에 저장된 테이블. 각 디스크 블록에는 동일한 열의 데이터가 포함. 예제 쿼리와 관련된 두 개의 열이 강조 표시되어 있다. 쿼리를 실행하려면 이러한 블록에만 액세스해야 합니다. 각 블록에는 동일한 유형의 데이터가 포함되어 있어 압축이 최적화됨.**

### **EtLT 하위 패턴 (EtLT Subpattern)**

ELT가 지배적인 패턴으로 등장했을 때, 추출 후 로드하기 전에 약간의 변환을 수행하는 것이 여전히 유익했음이 분명하다. 그러나 비즈니스 논리 또는 데이터 모델링과 관련된 변환 대신 이러한 유형의 변환의 범위는 더 제한적이긴 하다. 이것을 *소문자 t* 변환 또는 *EtLT (lowercase t-transformation, or EtLT)라고* 한다.

**EtLT 하위 패턴(EtLT Subpattern)에 맞는 변환 유형의 몇 가지 예**

- 테이블에서 레코드 중복 제거
- URL 매개변수를 개별 구성요소로 구문 분석
- 민감한 데이터 마스킹 또는 난독화

이러한 유형의 변환은 비즈니스 로직과 완전히 분리되거나, 민감한 데이터 마스킹과 같은 경우처럼 법적 또는 보안상의 이유로 파이프라인의 초기 단계에서 필요한 경우가 있다.  4장 과 5장 에서 자세히 설명하는 것처럼 대부분의 최신 데이터 웨어하우스는 데이터가 잘 준비되어 있으면 데이터를 가장 효율적으로 로드 한다. 많은 양의 데이터를 이동하는 파이프라인이나 대기 시간이 핵심인 경우 추출 단계와 로드 단계 사이에 몇 가지 기본 변환을 수행하는 것은 그만한 가치가 있다. 나머지 ELT 관련 패턴은 EtLT 하위 패턴도 포함하도록 설계되었다고 가정할 수 있다.
****

### **데이터 분석을 위한 ELT**

ELT는 데이터 분석을 위해 구축된 파이프라인에서 가장 일반적이고 가장 최적의 패턴이 되었다. 이미 논의한 바와 같이 컬럼 기반 데이터베이스는 대용량 데이터를 처리하는 데 적합하다. 또한 주어진 쿼리에 사용된 열의 데이터만 디스크에서 스캔되고 메모리에 로드된다는 사실 덕분에 넓은 테이블, 즉 많은 열이 있는 테이블을 처리하도록 설계되었다.

기술적인 고려 사항 외에도 데이터 분석가는 일반적으로 SQL에 능숙하다. ELT를 사용하면 데이터 엔지니어는 파이프라인(데이터 수집)의 추출 및 로드 단계에 집중할 수 있고 분석가는 SQL을 활용하여 보고 및 분석에 필요한 만큼 수집된 데이터를 변환할 수 있다. 그림 3-3 에서 볼 수 있듯이 ELT를 사용하면 데이터 팀 구성원이 상호 의존성과 조정을 줄이면서 자신의 강점에 집중할 수 있다.

또한 ELT 패턴은 추출 및 로드 프로세스를 구축할 때 분석가가 데이터로 수행할 작업을 정확히 예측할 필요성을 줄여준다. 적절한 데이터를 추출하고 로드하려면 일반적인 사용 사례를 이해해야 하지만 나중에 변환 단계를 저장하면 분석가에게 더 많은 옵션과 유연성을 제공할 수 있기 때문이다.

![https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492087823/files/assets/dppr_0303.png](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492087823/files/assets/dppr_0303.png)

**그림 3-3. ELT 패턴을 사용하면 데이터 엔지니어와 데이터 분석가(또는 데이터 과학자) 간의 책임을 명확하게 분할할 수 있다. 각 역할은 자신에게 익숙한 도구와 언어를 사용하여 자율적으로 작업할 수 있다.**

- **메모**
ELT의 등장으로 데이터 분석가는 데이터 엔지니어에 의해 "차단"되지 않고 데이터에서 가치를 제공할 수 있는 자율성과 권한을 갖게 되었다. 데이터 엔지니어는 분석가가 SQL로 작성된 자체 변환 코드를 작성하고 배포할 수 있도록 지원하는 인프라와 데이터 수집에 집중할 수 있다. *이러한 권한 부여와 함께 분석 엔지니어* 와 같은 새로운 직함이 생겼다 . 6장 에서는 이러한 데이터 분석가와 분석 엔지니어가 데이터를 변환하여 데이터 모델을 구축하는 방법에 대해 설명한다.

### **데이터 과학을 위한 ELT**

데이터 과학 팀을 위해 구축된 데이터 파이프라인은 데이터 웨어하우스에서 데이터 분석을 위해 구축된 파이프라인과 유사하다. 분석 사용 사례와 마찬가지로 데이터 엔지니어는 데이터 웨어하우스 또는 데이터 레이크에 데이터를 수집하는 데 중점을 둔다. 그러나 데이터 과학자는 데이터 분석가와 다른 요구 사항이 있다.

데이터 과학은 광범위한 분야이지만 일반적으로 데이터 과학자는 데이터 분석가보다 더 세분화된(때로는 원시) 데이터에 액세스해야 한다. 데이터 분석가가 메트릭을 생성하고 대시보드를 강화하는 데이터 모델을 구축하는 동안 데이터 과학자는 데이터를 탐색하고 예측 모델을 구축하는 데 하루를 보낸다. 데이터 과학자의 역할에 대한 자세한 내용은 이 책의 범위를 벗어났지만 이러한 상위 수준의 구분은 데이터 과학자에게 서비스를 제공하는 파이프라인 설계에 중요하다.

데이터 과학자를 지원하기 위해 파이프라인을 구축하는 경우 ELT 패턴의 추출 및 로드 단계가 분석 지원과 거의 동일하게 유지되며, ELT 파이프라인의 변환 단계  또한 분석가를 위해 구축된 일부 데이터 모델을 사용하여 이점을 얻을 수 있지만 추출 로드 중에 획득한 많은 데이터를 분기하여 사용할 가능성이 높다.

### **데이터 제품(Data Products) 및 기계 학습을 위한 ELT**

데이터는 분석, 보고 및 예측 모델 이상의 용도로 사용된다. 또한 *데이터 제품* 에 전원을 공급하는 데 사용된다. 

**데이터 제품(Data Products)의 몇 가지 일반적인 예**

- 비디오 스트리밍 홈 화면을 구동하는 콘텐츠 추천 엔진
- 전자 상거래 웹사이트의 개인화된 검색 엔진
- 사용자가 작성한 레스토랑 리뷰에 대한 감성 분석을 수행하는 애플리케이션

이러한 각 데이터 제품은 훈련 및 검증 데이터를 필요로 하는 하나 이상의 머신 러닝(ML) 모델에 의해 구동될 가능성이 높다. 이러한 데이터는 다양한 소스 시스템에서 가져올 수 있으며 모델에서 사용할 수 있도록 준비하기 위해 일정 수준의 변환을 거칠 수 있다. 데이터 제품을 위해 설계된 파이프라인의 모든 단계에서 많은 특정한 어려운 점들이 있지만 ELT와 유사한 패턴은 이러한 요구에 매우 적합하다.

- **기계 학습 파이프라인의 단계**
이 책에서 주로 초점을 맞춘 분석용으로 구축된 파이프라인과 마찬가지로 ML용으로 구축된 파이프라인은 적어도 파이프라인의 시작 부분에서 ELT와 유사한 패턴을 따른다.

**차이점**은 데이터를 데이터 모델로 변환하는 데 중점을 둔 변환 단계 대신 **데이터가 추출되어 웨어하우스 또는 데이터 레이크에 로드되면 ML 모델을 빌드하고 업데이트하는 데 관련된 여러 단계가 있다는 것**이다.

ML 개발에 익숙하다면 다음 단계도 익숙할 것이다.
    - **데이터 수집 단계** 
    : 4 장 과 5 장에서 설명한 것과 동일한 프로세스를 따른다. 로직은 ML뿐만 아니라 분석용으로 구축된 파이프라인에 대해 기본적으로 동일하게 유지되지만 ML 파이프라인에 대한 **한 가지 추가 고려 사항**이 있다. **ML 모델이 나중에 훈련 또는 검증을 위해 특정 데이터 세트로 참조할 수 있는 방식으로 수집하는 데이터의 버전이 지정되는지 확인해야한다.** 데이터세트 버전 관리를 위한 여러 도구와 접근 방식이 있습니다. 자세한 내용은 *"ML 파이프라인에 대한 추가 정보"* 를 참조하는 것이 좋다.
    
    - **데이터 전처리**
    : 수집된 데이터는 ML 개발에 사용할 준비가 되지 않았을 것이다. 전처리데이터가 정리되고 모델을 위해 준비되어야 한다. 예를 들어 텍스트가 토큰화되고, 기능이 숫자 값으로 변환되고, 입력 값이 정규화 되는 파이프라인의 단계이다.
    
    - **모델 교육**
    : 새로운 데이터가 수집되고 사전 처리된 후 ML모델을 재교육해야 한다.
    
    - **모델 배포**
    : 모델을 프로덕션에 배포하는 것은 연구 중심의 머신 러닝에서 진정한 데이터 제품으로 전환하는 데 있어 가장 어려운 부분이 될 수 있다. **여기서 데이터 세트의 버전 관리가 필요할 뿐만 아니라 훈련된 모델의 버전 관리도 필요하다.** 종종 REST API는 배포된 모델의 쿼리를 허용하는 데 사용되며 다양한 버전의 모델에 대한 API 엔드포인트가 사용된다. 생산 상태에 도달하기 위해 데이터 과학자, 기계 학습 엔지니어 및 데이터 엔지니어 간에 추적하고 조정해야 하는 일이 많다. 파이프라인이 잘 설계되어야 파이프라인을 함께 접착하는 데에도 좋다.
    
    - ****수집된 데이터 검증****
    8장 에서 논의한 바와 같이 파이프라인에서 데이터를 검증하는 것은 필수적이며 파이프라인 전반에 걸쳐 자리를 차지한다. 데이터 분석가를 위해 구축된 파이프라인에서 검증은 종종 데이터 수집(추출 로드) 및 데이터 모델링(변환) 후에 발생한다. ML 파이프라인에서는 **수집된 데이터의 유효성 검사도 중요하다.** 이 중요한 단계를 ML 개발의 표준 부분인 **ML 모델 자체의 검증과 혼동하지 말아야 한다.**
        
        
- **파이프라인에 피드백 통합**
좋은 ML 파이프라인에는 모델 개선을 위한 피드백 수집도 포함된다. 동영상 스트리밍 서비스의 콘텐츠 추천 모델을 예로 들어 보면, 향후 모델을 측정하고 개선하려면 모델이 사용자에게 무엇을 추천하는지, 어떤 추천 항목을 클릭하는지, 클릭한 후 어떤 추천 콘텐츠를 즐기는지 추적해야 한다. 그렇게 하려면 스트리밍 서비스 홈 화면에서 모델을 활용하는 개발 팀과 협력해야 한다. 그들은 각 사용자에 대한 각 권장 사항을 추적하는 일부 유형의 이벤트 수집을 구현해야 한다. [ 그것을 추천한 모델의 버전 ];[ 클릭했을 때 ]; [ 그런 다음 사용자의 콘텐츠 소비 와 관련하여 이미 수집하고 있는 데이터 ]로 클릭의 연결을 전달한다.

그런 다음 모든 정보를 데이터 웨어하우스로 다시 수집하고 교육 데이터로 또는 미래 모델 또는 실험에 포함하기 위해 인간(아마도 데이터 과학자)이 분석 및 고려할 모델의 향후 버전에 통합할 수 있다. 또한 수집된 데이터는 이 책에서 설명하는 ELT 패턴으로 데이터 분석가가 수집, 변환 및 분석할 수 있다.

<aside>
💡 **ML 파이프라인에 대한 추가 읽기**
기계 학습 모델을 위한 파이프라인 구축은 강력한 주제이기에 인프라 선택과 ML 환경의 복잡성에 따라 추가 학습을 위해 추천하는 몇 권의 책이 있다.

• Building Machine Learning Pipelines by Hannes Hapke and Catherine Nelson (O’Reilly, 2020)
• Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd edition, by Aurélien Géron (O’Reilly, 2019)
• Introduction to Machine Learning with Python by Andreas C. Müller and Sarah Guido (O’Reilly, 2016)

</aside>